{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e2528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d536930",
   "metadata": {},
   "source": [
    "extract two ways relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4e73693",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "rootdir=os.getcwd()+'/dataset/' \n",
    "directories=[]\n",
    "for file in os.listdir(rootdir):\n",
    "    d = os.path.join(rootdir, file)\n",
    "    if os.path.isdir(d):\n",
    "        directories.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2744966",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas={}\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "for i in directories:\n",
    "    pref=str(i.split('/')[-1])\n",
    "    files = [f for f in listdir(i) if isfile(join(i, f))]\n",
    "    for f in files:\n",
    "        if f[-4:]=='.txt':\n",
    "            suf=f[:-4]\n",
    "            name=pref+suf\n",
    "            with open(i+'/'+f, \"r\") as file:\n",
    "                data = file.read().replace(\"\\n\", \"\")\n",
    "            article = data.replace(u\"\\xa0\", u\" \")\n",
    "            datas[name]=nlp(article)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63a9805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_names = [f for f in datas.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6b1c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5211d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_entities(text):\n",
    "    ents_=text.ents\n",
    "    ents=[]\n",
    "    for x in ents_:\n",
    "        if x.text not in ents:\n",
    "            if x.label_==\"ORG\" or x.label_==\"PRODUCT\" or x.label_==\"GPE\":\n",
    "                ents.append(x.text)\n",
    "    return ents\n",
    "\n",
    "\n",
    "def find_org(s, ents):\n",
    "    i=0\n",
    "    ind=[]\n",
    "    for token in s:\n",
    "        if str(token) in ents: \n",
    "            ind.append(i)\n",
    "        i=i+1\n",
    "    return ind\n",
    "\n",
    "def check_synonym_SVO(s, list_):\n",
    "    for token in s:\n",
    "        if token.dep_==\"ROOT\":\n",
    "            lem=token.lemma_\n",
    "            if lem in list_:\n",
    "                return True\n",
    "            else:\n",
    "                return False      \n",
    "\n",
    "def find_sbj(s, ind):\n",
    "    subjects=[]\n",
    "    for i in ind:\n",
    "        if s[i].dep_==\"nsubj\":\n",
    "            subjects.append(s[i])\n",
    "        elif s[i].head.dep_==\"nsubj\": # walk one step up the dependency tree \n",
    "            subjects.append(s[i])\n",
    "        else:\n",
    "            continue # could move one more step up the dependency tree if we condition was came up before (excluding object and verbs)\n",
    "    return subjects\n",
    "\n",
    "def find_nsubjpass(s, ind):\n",
    "    subjects=[]\n",
    "    for i in ind:\n",
    "        if s[i].dep_==\"nsubjpass\":\n",
    "            subjects.append(s[i])\n",
    "        elif s[i].head.dep_==\"nsubjpass\": # walk one step up the dependency tree \n",
    "            subjects.append(s[i])\n",
    "        else:\n",
    "            continue # could move one more step up the dependency tree if we condition was came up before (excluding object and verbs)\n",
    "    return subjects\n",
    "            \n",
    "def find_obj(s, ind):\n",
    "    subjects=[]\n",
    "    for i in ind:\n",
    "        if s[i].dep_==\"dobj\" or s[i].dep_==\"pobj\":\n",
    "            subjects.append(s[i])\n",
    "        elif s[i].head.dep_==\"dobj\" or s[i].head.dep_==\"pobj\": # walk one step up the dependency tree \n",
    "            subjects.append(s[i])\n",
    "        else:\n",
    "            continue\n",
    "    return subjects\n",
    "\n",
    "def check_synonym_attr(s, list_):\n",
    "    for token in s:\n",
    "        if token.dep_==\"attr\":\n",
    "            lem=token.lemma_\n",
    "            if lem in list_:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "            \n",
    "def find_obj_attr(s, ind):\n",
    "    subjects=[]\n",
    "    for i in ind:\n",
    "        if s[i].dep_==\"pobj\":\n",
    "            subjects.append(s[i])\n",
    "        elif s[i].head.dep_==\"pobj\": # walk one step up the dependency tree \n",
    "            subjects.append(s[i])\n",
    "        else:\n",
    "            continue\n",
    "    return subjects\n",
    "\n",
    "def check_synonym_acl(s, list_):\n",
    "    for token in s:\n",
    "        if token.dep_==\"acl\":\n",
    "            lem=token.lemma_\n",
    "            if lem in list_:\n",
    "                return True\n",
    "            else:\n",
    "                return False  \n",
    "\n",
    "def find_obj_acl(s, ind):\n",
    "    subjects=[]\n",
    "    for i in ind:\n",
    "        if s[i].dep_==\"pobj\":\n",
    "            subjects.append(s[i])\n",
    "        elif s[i].head.dep_==\"pobj\": # walk one step up the dependency tree \n",
    "            subjects.append(s[i])\n",
    "        else:\n",
    "            continue\n",
    "    return subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f8fda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61b1ff6a",
   "metadata": {},
   "source": [
    "# SVO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52de34e9",
   "metadata": {},
   "source": [
    "Get synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "697a87c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sale', 'sale', 'sale', 'cut-rate_sale', 'sales_event', 'sale', 'sale', 'sales_agreement']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "synonyms = []\n",
    "antonyms = []\n",
    "  \n",
    "for syn in wordnet.synsets(\"sale\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "print(synonyms)\n",
    "print(antonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42dd48e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['supply', 'provide', 'render', 'furnish', 'provide', 'supply', 'ply', 'cater', 'provide', 'put_up', 'provide', 'offer', 'leave', 'allow_for', 'allow', 'provide', 'provide', 'bring_home_the_bacon', 'provide']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "synonyms = []\n",
    "antonyms = []\n",
    "  \n",
    "for syn in wordnet.synsets(\"provide\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "print(synonyms)\n",
    "print(antonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bd15fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['supply', 'provide', 'render', 'furnish', 'furnish']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "synonyms = []\n",
    "antonyms = []\n",
    "  \n",
    "for syn in wordnet.synsets(\"furnish\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "print(synonyms)\n",
    "print(antonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e919ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples=[]\n",
    "relation=\"sales_product\"\n",
    "synonyms=[\"supply\",\"provision\",\"provide\",\"furnish\",\"render\"] # have is too misleading\n",
    "for i in text_names:\n",
    "    text=datas[i]\n",
    "    ents=list_entities(text)\n",
    "    for s in text.sents:\n",
    "        dict_={}\n",
    "        org=find_org(s,ents)\n",
    "        if len(org)>=2:\n",
    "            SVO=check_synonym_SVO(s,synonyms)\n",
    "            if SVO==True:\n",
    "                sbj=find_sbj(s,org)\n",
    "                if len(sbj)>0: \n",
    "                    obj=find_obj(s,org)\n",
    "                    if len(obj)>0:\n",
    "                        dict_['relation']=relation\n",
    "                        ## add ID later dict_['relation']\n",
    "                        dict_['sentence']=s\n",
    "                        dict_['entities_A']=sbj\n",
    "                        dict_['entities_B']=obj\n",
    "                        tuples.append(dict_)\n",
    "                else:\n",
    "                    nsubjpass=find_nsubjpass(s,org)\n",
    "                    if len(nsubjpass)>0:\n",
    "                        obj=find_obj(s,org)\n",
    "                        if len(obj)>0:\n",
    "                            dict_['relation']=relation\n",
    "                            ## add ID later dict_['relation']\n",
    "                            dict_['sentence']=s\n",
    "                            dict_['entities_A']=obj\n",
    "                            dict_['entities_B']=sbj\n",
    "                            tuples.append(dict_)\n",
    "                    else:\n",
    "                        continue\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            continue    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffb6f521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27cb32ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'relation': 'suppliers',\n",
       "  'sentence': In addition, SoftBank is providing an additional $300 million equity commitment that can be drawn at the Company's discretion.,\n",
       "  'entities_A': [SoftBank],\n",
       "  'entities_B': [Company]},\n",
       " {'relation': 'suppliers',\n",
       "  'sentence': \"About Cepton Technologies, Inc.Cepton provides state-of-the-art, intelligent, lidar-based solutions for a range of markets such as automotive (ADAS/AV), smartcities, smart spaces and smart industrial applications.,\n",
       "  'entities_A': [Cepton],\n",
       "  'entities_B': [Cepton]},\n",
       " {'relation': 'suppliers',\n",
       "  'sentence': \"Adverse events (AEs) reported in the GRIPHON and TRITON clinical trials were consistent with the known safety profiles of the studies' medications.7,8# # #*Dr Coghlan has provided paid consultancy services for Janssen in relation to research and advisory boards.,\n",
       "  'entities_A': [TRITON],\n",
       "  'entities_B': [GRIPHON]},\n",
       " {'relation': 'suppliers',\n",
       "  'sentence': About Cepton Technologies, Inc.Cepton provides state-of-the-art, intelligent, lidar-based solutions for a range of markets such as automotive (ADAS/AV), smartcities, smart spaces and smart industrial applications.,\n",
       "  'entities_A': [Cepton],\n",
       "  'entities_B': [Cepton]}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bafa206",
   "metadata": {},
   "source": [
    "Again, identifies products need to changeidentity NER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6bfd5c",
   "metadata": {},
   "source": [
    "# attributes kind of patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20fa390e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['supplier', 'provider']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "synonyms = []\n",
    "antonyms = []\n",
    "  \n",
    "for syn in wordnet.synsets(\"supplier\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "print(synonyms)\n",
    "print(antonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62d1d8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['supplier', 'provider', 'provider']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "synonyms = []\n",
    "antonyms = []\n",
    "  \n",
    "for syn in wordnet.synsets(\"provider\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "print(synonyms)\n",
    "print(antonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "044005b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples=[]\n",
    "relation=\"suppliers\"  \n",
    "synonyms=[\"supplier\",\"provider\"]\n",
    "for i in text_names:\n",
    "    text=datas[i]\n",
    "    ents=list_entities(text)\n",
    "    for s in text.sents:\n",
    "        dict_={}\n",
    "        org=find_org(s,ents)\n",
    "        if len(org)>=2:\n",
    "            attr=check_synonym_attr(s,synonyms)\n",
    "            if attr==True:\n",
    "                sbj=find_sbj(s,org)\n",
    "                if len(sbj)>0: \n",
    "                    obj=find_obj_attr(s,org)\n",
    "                    if len(obj)>0:\n",
    "                        dict_['relation']=relation\n",
    "                        ## add ID later dict_['relation']\n",
    "                        dict_['sentence']=s\n",
    "                        dict_['entities_A']=sbj\n",
    "                        dict_['entities_B']=obj\n",
    "                        tuples.append(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae2bbafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'relation': 'suppliers',\n",
       "  'sentence': With Lionbridge AI integration activities well-underway since the start of the year, TELUS International is able to meet these heightened and critical requirements while simultaneously meeting our clients' digital transformation needs across the full customer experience value chain, ultimately defining a new market category at the intersection of digital IT and digital CX.\"Lionbridge AI is a leading and global provider of scalable data annotation services for text, images, videos, and audio.,\n",
       "  'entities_A': [AI],\n",
       "  'entities_B': [AI]},\n",
       " {'relation': 'suppliers',\n",
       "  'sentence': This would \"shatter any EU illusions that Russia is a reliable supplier\" and would likely trigger a \"concerted effort\" within the bloc to \"permanently reduce gas imports from Russia as soon as possible,\" he added.,\n",
       "  'entities_A': [Russia],\n",
       "  'entities_B': [Russia]}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff1f09cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nothing relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09d6f0f",
   "metadata": {},
   "source": [
    "# ACL based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78d22b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples=[]\n",
    "relation=\"suppliers\"\n",
    "synonyms=[\"supply\",\"provision\",\"provide\",\"furnish\",\"render\"] # have is too misleading\n",
    "for i in text_names:\n",
    "    text=datas[i]\n",
    "    ents=list_entities(text)\n",
    "    for s in text.sents:\n",
    "        dict_={}\n",
    "        org=find_org(s,ents)\n",
    "        if len(org)>=2:\n",
    "            acl=check_synonym_acl(s,synonyms)\n",
    "            if acl==True:\n",
    "                sbj=find_sbj(s,org)\n",
    "                if len(sbj)>0: \n",
    "                    obj=find_obj_acl(s,org)\n",
    "                    if len(obj)>0:\n",
    "                        dict_['relation']=relation\n",
    "                        ## add ID later dict_['relation']\n",
    "                        dict_['sentence']=s\n",
    "                        dict_['entities_A']=sbj\n",
    "                        dict_['entities_B']=obj\n",
    "                        tuples.append(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a09a049b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'relation': 'suppliers',\n",
       "  'sentence': MWCTravel service provided at no charge to MWC21 participants travelling to Barcelona19 April 2021, London: Today, GSMA introduces Gray Dawes Travel as MWC21 Barcelona business travel partner.,\n",
       "  'entities_A': [London, GSMA],\n",
       "  'entities_B': [Barcelona19, Barcelona]}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a130aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same use ORG although nothing comes up with ORG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c02d09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "spacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
