{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e2528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4e73693",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(os.getcwd()))\n",
    "rootdir=os.getcwd()+'/dataset/' \n",
    "directories=[]\n",
    "for file in os.listdir(rootdir):\n",
    "    d = os.path.join(rootdir, file)\n",
    "    if os.path.isdir(d):\n",
    "        directories.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2744966",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas={}\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import neuralcoref\n",
    "neuralcoref.add_to_pipe(nlp)\n",
    "nlp_ = spacy.load(\"en_core_web_sm\")\n",
    "for i in directories:\n",
    "    pref=str(i.split('/')[-1])\n",
    "    files = [f for f in listdir(i) if isfile(join(i, f))]\n",
    "    for f in files:\n",
    "        if f[-4:]=='.txt':\n",
    "            suf=f[:-4]\n",
    "            name=pref+suf\n",
    "            with open(i+'/'+f, \"r\") as file:\n",
    "                data = file.read().replace(\"\\n\", \"\")\n",
    "            article = data.replace(u\"\\xa0\", u\" \")\n",
    "            datas[name]=nlp(article)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63a9805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_names = [f for f in datas.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6b1c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5211d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_entities(text):\n",
    "    ents_=text.ents\n",
    "    ents=[]\n",
    "    for x in ents_:\n",
    "        if x.text not in ents:\n",
    "            if x.label_==\"ORG\" or x.label_==\"PRODUCT\" or x.label_==\"GPE\":\n",
    "                ents.append(x.text)\n",
    "    return ents\n",
    "\n",
    "\n",
    "def find_org(s, ents):\n",
    "    i=0\n",
    "    ind=[]\n",
    "    for token in s:\n",
    "        if str(token) in ents: \n",
    "            ind.append(i)\n",
    "        i=i+1\n",
    "    return ind\n",
    "\n",
    "def check_synonym_SVO(s, list_):\n",
    "    for token in s:\n",
    "        if token.dep_==\"ROOT\":\n",
    "            lem=token.lemma_\n",
    "            if lem in list_:\n",
    "                return True\n",
    "            else:\n",
    "                return False      \n",
    "\n",
    "def find_sbj(s, ind):\n",
    "    subjects=[]\n",
    "    for i in ind:\n",
    "        if s[i].dep_==\"nsubj\":\n",
    "            subjects.append(s[i])\n",
    "        elif s[i].head.dep_==\"nsubj\": # walk one step up the dependency tree \n",
    "            subjects.append(s[i])\n",
    "        else:\n",
    "            continue # could move one more step up the dependency tree if we condition was came up before (excluding object and verbs)\n",
    "    return subjects\n",
    "\n",
    "def find_nsubjpass(s, ind):\n",
    "    subjects=[]\n",
    "    for i in ind:\n",
    "        if s[i].dep_==\"nsubjpass\":\n",
    "            subjects.append(s[i])\n",
    "        elif s[i].head.dep_==\"nsubjpass\": # walk one step up the dependency tree \n",
    "            subjects.append(s[i])\n",
    "        else:\n",
    "            continue # could move one more step up the dependency tree if we condition was came up before (excluding object and verbs)\n",
    "    return subjects\n",
    "            \n",
    "def find_obj(s, ind):\n",
    "    subjects=[]\n",
    "    for i in ind:\n",
    "        if s[i].dep_==\"dobj\" or s[i].dep_==\"pobj\":\n",
    "            subjects.append(s[i])\n",
    "        elif s[i].head.dep_==\"dobj\" or s[i].head.dep_==\"pobj\": # walk one step up the dependency tree \n",
    "            subjects.append(s[i])\n",
    "        else:\n",
    "            continue\n",
    "    return subjects\n",
    "\n",
    "def check_synonym_attr(s, list_):\n",
    "    for token in s:\n",
    "        if token.dep_==\"attr\":\n",
    "            lem=token.lemma_\n",
    "            if lem in list_:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "            \n",
    "def find_obj_attr(s, ind):\n",
    "    subjects=[]\n",
    "    for i in ind:\n",
    "        if s[i].dep_==\"pobj\":\n",
    "            subjects.append(s[i])\n",
    "        elif s[i].head.dep_==\"pobj\": # walk one step up the dependency tree \n",
    "            subjects.append(s[i])\n",
    "        else:\n",
    "            continue\n",
    "    return subjects\n",
    "\n",
    "def check_synonym_acl(s, list_):\n",
    "    for token in s:\n",
    "        if token.dep_==\"acl\":\n",
    "            lem=token.lemma_\n",
    "            if lem in list_:\n",
    "                return True\n",
    "            else:\n",
    "                return False  \n",
    "\n",
    "def find_obj_acl(s, ind):\n",
    "    subjects=[]\n",
    "    for i in ind:\n",
    "        if s[i].dep_==\"pobj\":\n",
    "            subjects.append(s[i])\n",
    "        elif s[i].head.dep_==\"pobj\": # walk one step up the dependency tree \n",
    "            subjects.append(s[i])\n",
    "        else:\n",
    "            continue\n",
    "    return subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f8fda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61b1ff6a",
   "metadata": {},
   "source": [
    "# SVO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52de34e9",
   "metadata": {},
   "source": [
    "Get synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "697a87c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['own', 'have', 'possess', 'own', 'ain']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "synonyms = []\n",
    "antonyms = []\n",
    "  \n",
    "for syn in wordnet.synsets(\"own\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "print(synonyms)\n",
    "print(antonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8702f3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['get', 'acquire', 'assume', 'acquire', 'adopt', 'take_on', 'take', 'grow', 'develop', 'produce', 'get', 'acquire', 'acquire', 'acquire', 'win', 'gain', 'learn', 'larn', 'acquire', 'develop', 'acquire', 'evolve']\n",
      "['lose']\n"
     ]
    }
   ],
   "source": [
    "synonyms = []\n",
    "antonyms = []\n",
    "  \n",
    "for syn in wordnet.synsets(\"acquire\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "print(synonyms)\n",
    "print(antonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14a31dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['purchase', 'purchase', 'purchase', 'leverage', 'purchase', 'buy', 'purchase']\n",
      "['sell']\n"
     ]
    }
   ],
   "source": [
    "synonyms = []\n",
    "antonyms = []\n",
    "  \n",
    "for syn in wordnet.synsets(\"purchase\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "print(synonyms)\n",
    "print(antonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dd48e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e919ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples=[]\n",
    "relation=\"ownership\"\n",
    "synonyms=[\"buy\",\"acquire\",\"purchase\",\"own\",\"gain\",\"possess\"] # have is too misleading\n",
    "for i in text_names:\n",
    "    text=datas[i]._.coref_resolved\n",
    "    text=nlp_(text)\n",
    "    ents=list_entities(text)\n",
    "    for s in text.sents:\n",
    "        dict_={}\n",
    "        org=find_org(s,ents)\n",
    "        if len(org)>=2:\n",
    "            SVO=check_synonym_SVO(s,synonyms)\n",
    "            if SVO==True:\n",
    "                sbj=find_sbj(s,org)\n",
    "                if len(sbj)>0: \n",
    "                    obj=find_obj(s,org)\n",
    "                    if len(obj)>0:\n",
    "                        dict_['relation']=relation\n",
    "                        ## add ID later dict_['relation']\n",
    "                        dict_['sentence']=s\n",
    "                        dict_['entities_A']=sbj\n",
    "                        dict_['entities_B']=obj\n",
    "                        tuples.append(dict_)\n",
    "                else:\n",
    "                    nsubjpass=find_nsubjpass(s,org)\n",
    "                    if len(nsubjpass)>0:\n",
    "                        obj=find_obj(s,org)\n",
    "                        if len(obj)>0:\n",
    "                            dict_['relation']=relation\n",
    "                            ## add ID later dict_['relation']\n",
    "                            dict_['sentence']=s\n",
    "                            dict_['entities_A']=obj\n",
    "                            dict_['entities_B']=sbj\n",
    "                            tuples.append(dict_)\n",
    "                    else:\n",
    "                        continue\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            continue    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffb6f521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27cb32ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'relation': 'ownership',\n",
       "  'sentence': Boohoo on Monday bought the remaining fashion brands belonging to Arcadia -- the collapsed bricks-and-mortar business that had struggled long before the Covid-19 pandemic forced shoppers online.,\n",
       "  'entities_A': [Boohoo],\n",
       "  'entities_B': [Arcadia]},\n",
       " {'relation': 'ownership',\n",
       "  'sentence': Russia own payment system, SPFS, after Russia was hit by Western sanctions in 2014 following Russia annexation of Crimea early that year.,\n",
       "  'entities_A': [Russia],\n",
       "  'entities_B': [SPFS, Russia, Crimea]}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d3d59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e6bfd5c",
   "metadata": {},
   "source": [
    "# attributes kind of patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fb9d4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['company', 'company', 'company', 'companionship', 'fellowship', 'society', 'company', 'troupe', 'caller', 'company', 'company', 'party', 'company', \"ship's_company\", 'company', 'company', 'company', 'companion', 'accompany', 'keep_company']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "synonyms = []\n",
    "antonyms = []\n",
    "  \n",
    "for syn in wordnet.synsets(\"company\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "print(synonyms)\n",
    "print(antonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad6ea632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['branch', 'subdivision', 'arm', 'branch', 'branch', 'leg', 'ramification', 'outgrowth', 'branch', 'offshoot', 'offset', 'branch', 'arm', 'branch', 'limb', 'ramify', 'branch', 'branch', 'ramify', 'fork', 'furcate', 'separate']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "synonyms = []\n",
    "antonyms = []\n",
    "  \n",
    "for syn in wordnet.synsets(\"branch\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "print(synonyms)\n",
    "print(antonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db0f9a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['firm', 'house', 'business_firm', 'tauten', 'firm', 'tauten', 'firm', 'firm', 'steadfast', 'steady', 'stiff', 'unbendable', 'unfaltering', 'unshakable', 'unwavering', 'firm', 'solid', 'firm', 'strong', 'firm', 'firm', 'firm', 'steady', 'unfluctuating', 'firm', 'firm', 'fast', 'firm', 'immobile', 'firm', 'loyal', 'truehearted', 'fast', 'firm', 'firmly', 'steadfastly', 'unwaveringly']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "synonyms = []\n",
    "antonyms = []\n",
    "  \n",
    "for syn in wordnet.synsets(\"firm\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "print(synonyms)\n",
    "print(antonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "044005b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples=[]\n",
    "relation=\"is_owner\"  \n",
    "synonyms=[\"company\",\"firm\",\"branch\",\"business_firm\"]\n",
    "for i in text_names:\n",
    "    text=datas[i]._.coref_resolved\n",
    "    text=nlp_(text)\n",
    "    ents=list_entities(text)\n",
    "    for s in text.sents:\n",
    "        dict_={}\n",
    "        org=find_org(s,ents)\n",
    "        if len(org)>=2:\n",
    "            attr=check_synonym_attr(s,synonyms)\n",
    "            if attr==True:\n",
    "                sbj=find_sbj(s,org)\n",
    "                if len(sbj)>0: \n",
    "                    obj=find_obj_attr(s,org)\n",
    "                    if len(obj)>0:\n",
    "                        dict_['relation']=relation\n",
    "                        ## add ID later dict_['relation']\n",
    "                        dict_['sentence']=s\n",
    "                        dict_['entities_A']=sbj\n",
    "                        dict_['entities_B']=obj\n",
    "                        tuples.append(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae2bbafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'relation': 'is_owner',\n",
       "  'sentence': Kymeta is a privately held company based in Redmond, Washington.,\n",
       "  'entities_A': [Kymeta],\n",
       "  'entities_B': [Redmond, Washington]},\n",
       " {'relation': 'is_owner',\n",
       "  'sentence': Exscientia is the first company to progress AI-designed small molecules into the clinical setting and repeatedly demonstrate the ability of AI to transform how drugs are created.,\n",
       "  'entities_A': [Exscientia],\n",
       "  'entities_B': [AI]},\n",
       " {'relation': 'is_owner',\n",
       "  'sentence': Created in 2015, Dawex is a tech company with offices in France and Canada, expanding business operations to Asia and the Middle East.,\n",
       "  'entities_A': [Dawex],\n",
       "  'entities_B': [France, Canada]},\n",
       " {'relation': 'is_owner',\n",
       "  'sentence': Barbara Cahill, Senior Global Portfolio Manager for Immunohistochemistry, Consumables and Cytology, EprediaDisclaimer:1 Not sponsored by Lunaphore.2 Sponsored by Epredia, exclusive distributor of LabSat® in the US, Germany and UK.About LunaphoreLunaphore Technologies S.A. is a Swiss company born in 2014 with the vision of enabling spatial biology in every laboratory.,\n",
       "  'entities_A': [Germany],\n",
       "  'entities_B': [Sponsored, Epredia, LabSat, US]},\n",
       " {'relation': 'is_owner',\n",
       "  'sentence': Samsung has Samsung new Exynos 2200 processor, which will mix things up a bit with an AMD 2-powered GPU, but odds are it won’t ever make it to the US for a variety of licensing and modem issues (along with the simple fact that Qualcomm’s chips historically perform better than Samsung’s).Google is a company to watch, with Samsung new Tensor SoC platform that Samsung debuted on the Pixel 6 lineup last year; presumably, Google will be looking to follow that up with a second-generation version to power Samsung 2022 smartphones.,\n",
       "  'entities_A': [Samsung, Qualcomm, Samsung, Google],\n",
       "  'entities_B': [AMD, GPU, US, Samsung’s).Google, Samsung, Pixel]}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1f09cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f09d6f0f",
   "metadata": {},
   "source": [
    "# ACL based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78d22b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples=[]\n",
    "relation=\"ownership\"\n",
    "synonyms=[\"buy\",\"acquire\",\"purchase\",\"own\",\"gain\",\"possess\"] # have is too misleading\n",
    "for i in text_names:\n",
    "    text=datas[i]._.coref_resolved\n",
    "    text=nlp_(text)\n",
    "    ents=list_entities(text)\n",
    "    for s in text.sents:\n",
    "        dict_={}\n",
    "        org=find_org(s,ents)\n",
    "        if len(org)>=2:\n",
    "            acl=check_synonym_acl(s,synonyms)\n",
    "            if acl==True:\n",
    "                sbj=find_sbj(s,org)\n",
    "                if len(sbj)>0: \n",
    "                    obj=find_obj_acl(s,org)\n",
    "                    if len(obj)>0:\n",
    "                        dict_['relation']=relation\n",
    "                        ## add ID later dict_['relation']\n",
    "                        dict_['sentence']=s\n",
    "                        dict_['entities_A']=sbj\n",
    "                        dict_['entities_B']=obj\n",
    "                        tuples.append(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a09a049b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'relation': 'ownership',\n",
       "  'sentence': UMS, owned by French-Lebanese-Guinean businessman Fadi Wazni, will take on part of Alteo's debt and phase out the import of bauxite, a raw material for aluminium production, within 12 to 18 months because of aluminium production environmental impact.,\n",
       "  'entities_A': [UMS],\n",
       "  'entities_B': [Alteo]},\n",
       " {'relation': 'ownership',\n",
       "  'sentence': About 13,000 jobs in total are being lost owing to Arcadia's collapse in December, marking the spectacular collapse of the sprawling retail empire.13,000 jobs in total have either been made redundant since administration, or or are now at risk of being lost, according to a source close to the matter.administrator Deloitte, in charge of winding down the once-mighty high street giant owned by British tycoon Philip Green, said Monday that Boohoo is paying £25.2 million ($34.6 million, 28.7 million euros) for the three brands.,\n",
       "  'entities_A': [Boohoo],\n",
       "  'entities_B': [Arcadia, Deloitte]},\n",
       " {'relation': 'ownership',\n",
       "  'sentence': Samsung reported solid earnings of Samsung own in Seoul on Thursday, with a 53% jump in operating profit for the fourth quarter, compared with that of the previous year.,\n",
       "  'entities_A': [Samsung],\n",
       "  'entities_B': [Samsung, Seoul]}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a130aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c02d09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coref3.7",
   "language": "python",
   "name": "coref3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
