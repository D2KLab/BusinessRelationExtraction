{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36aebe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f092e25e",
   "metadata": {},
   "source": [
    "Le but de ce notebook est de définir 3 grande techniques pour extraire des relations en s'appuyant sur trois grandes bases grammatical et les graphs de dependency de spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc7e6ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir=os.getcwd()+'/dataset/' \n",
    "directories=[]\n",
    "for file in os.listdir(rootdir):\n",
    "    d = os.path.join(rootdir, file)\n",
    "    if os.path.isdir(d):\n",
    "        directories.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05bd1975",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas={}\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "for i in directories:\n",
    "    pref=str(i.split('/')[-1])\n",
    "    files = [f for f in listdir(i) if isfile(join(i, f))]\n",
    "    for f in files:\n",
    "        if f[-4:]=='.txt':\n",
    "            suf=f[:-4]\n",
    "            name=pref+suf\n",
    "            with open(i+'/'+f, \"r\") as file:\n",
    "                data = file.read().replace(\"\\n\", \"\")\n",
    "            article = data.replace(u\"\\xa0\", u\" \")\n",
    "            datas[name]=nlp(article)\n",
    "        \n",
    "# saves doc object in datas dictionary for all articles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b9002d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_names = [f for f in datas.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa38043",
   "metadata": {},
   "source": [
    "list of dependency labels\n",
    "https://github.com/clir/clearnlp-guidelines/blob/master/md/specifications/dependency_labels.md\n",
    "\n",
    "https://downloads.cs.stanford.edu/nlp/software/dependencies_manual.pdf (descriptions)\n",
    "\n",
    "https://suttipong-kull.medium.com/how-to-extract-subject-verb-and-object-by-nlp-4149323a7d7d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33de6524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e126d19c",
   "metadata": {},
   "source": [
    "# Note: All extractions work better with Coreference resolution before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669a537a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63fcd45e",
   "metadata": {},
   "source": [
    "# SVO construction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5772587",
   "metadata": {},
   "source": [
    "Simple sentences subject-verbe-object. It aims to extract two-entity tuples, given a selected set of verbs \n",
    "\n",
    "!!! note ORG are recognize if starting with capital letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "565abb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Facebook   NNP      nsubj     bought PROPN\n",
      "    bought   VBD       ROOT     bought VERB\n",
      " instagram    NN       dobj     bought NOUN\n",
      "       and    CC         cc  instagram CCONJ\n",
      "  whatsapp    NN       conj  instagram NOUN\n"
     ]
    }
   ],
   "source": [
    "test3=nlp(\"Facebook bought instagram and whatsapp\")\n",
    "for s in test3.sents:\n",
    "    for token in s:\n",
    "        print('%10s %5s %10s %10s %s'%(token.text, token.tag_, token.dep_, token.head, token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10eb7c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Twitter   NNP  nsubjpass     bought PROPN\n",
      "       was   VBD    auxpass     bought AUX\n",
      "    bought   VBN       ROOT     bought VERB\n",
      "        by    IN      agent     bought ADP\n",
      "  facebook   NNP       pobj         by PROPN\n"
     ]
    }
   ],
   "source": [
    "# passive is detected with nsubjpass and auxpass\n",
    "test=nlp(\"Twitter was bought by facebook\")\n",
    "for s in test.sents:\n",
    "    for token in s:\n",
    "        print('%10s %5s %10s %10s %s'%(token.text, token.tag_, token.dep_, token.head, token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d147c3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Instagram   NNP      nsubj    compete PROPN\n",
      "       and    CC         cc  Instagram CCONJ\n",
      "       its  PRP$       poss      owner PRON\n",
      "     owner    NN       conj  Instagram NOUN\n",
      "  Facebook   NNP      appos      owner PROPN\n",
      "   compete    VB       ROOT    compete VERB\n",
      "      with    IN       prep    compete ADP\n",
      "    tiktok    NN       pobj       with NOUN\n"
     ]
    }
   ],
   "source": [
    "test3=nlp(\"Instagram and its owner Facebook compete with tiktok\")\n",
    "for s in test3.sents:\n",
    "    for token in s:\n",
    "        print('%10s %5s %10s %10s %s'%(token.text, token.tag_, token.dep_, token.head, token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396efac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9c5b4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Twitter]\n"
     ]
    }
   ],
   "source": [
    "for s in test.sents:\n",
    "    print(s.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41bf0410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence entities types\n",
      "PRODUCT\n"
     ]
    }
   ],
   "source": [
    "for s in test.sents:\n",
    "    print(\"sentence entities types\")\n",
    "    for t in s.ents:\n",
    "        print(t.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c672da6e",
   "metadata": {},
   "source": [
    "Cela montre que spacy mispecify souvent les \"organisations\". certaines entitées ne sortent pas également (comme Facebook sur la deuxième phrase). Les entités en minuscules ne sont aussi pas relevées. Celà suggère qu'il faut peut être parser les entitées à partir d'une base de données d'entreprises. Note: Compute entities at the article level scales down the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b366773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_entities(text):\n",
    "    ents_=text.ents\n",
    "    ents=[]\n",
    "    for x in ents_:\n",
    "        if x.text not in ents:\n",
    "            if x.label_==\"ORG\" or x.label_==\"PRODUCT\" or x.label_==\"GPE\":\n",
    "                ents.append(x.text)\n",
    "    return ents\n",
    "\n",
    "\n",
    "def find_org(s, ents):\n",
    "    i=0\n",
    "    ind=[]\n",
    "    for token in s:\n",
    "        if str(token) in ents: \n",
    "            ind.append(i)\n",
    "        i=i+1\n",
    "    return ind\n",
    "\n",
    "def check_synonym_SVO(s, list_):\n",
    "    for token in s:\n",
    "        if token.dep_==\"ROOT\":\n",
    "            lem=token.lemma_\n",
    "            if lem in list_:\n",
    "                return True\n",
    "            else:\n",
    "                return False      \n",
    "\n",
    "def find_sbj(s, ind):\n",
    "    subjects=[]\n",
    "    for i in ind:\n",
    "        if s[i].dep_==\"nsubj\":\n",
    "            subjects.append(s[i])\n",
    "        elif s[i].head.dep_==\"nsubj\": # walk one step up the dependency tree \n",
    "            subjects.append(s[i])\n",
    "        else:\n",
    "            continue # could move one more step up the dependency tree if we condition was came up before (excluding object and verbs)\n",
    "    return subjects\n",
    "\n",
    "def find_nsubjpass(s, ind):\n",
    "    subjects=[]\n",
    "    for i in ind:\n",
    "        if s[i].dep_==\"nsubjpass\":\n",
    "            subjects.append(s[i])\n",
    "        elif s[i].head.dep_==\"nsubjpass\": # walk one step up the dependency tree \n",
    "            subjects.append(s[i])\n",
    "        else:\n",
    "            continue # could move one more step up the dependency tree if we condition was came up before (excluding object and verbs)\n",
    "    return subjects\n",
    "            \n",
    "def find_obj(s, ind):\n",
    "    subjects=[]\n",
    "    for i in ind:\n",
    "        if s[i].dep_==\"dobj\" or s[i].dep_==\"pobj\":\n",
    "            subjects.append(s[i])\n",
    "        elif s[i].head.dep_==\"dobj\" or s[i].head.dep_==\"pobj\": # walk one step up the dependency tree \n",
    "            subjects.append(s[i])\n",
    "        else:\n",
    "            continue\n",
    "    return subjects\n",
    "\n",
    "def check_synonym_attr(s, list_):\n",
    "    for token in s:\n",
    "        if token.dep_==\"attr\":\n",
    "            lem=token.lemma_\n",
    "            if lem in list_:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "            \n",
    "def find_obj_attr(s, ind):\n",
    "    subjects=[]\n",
    "    for i in ind:\n",
    "        if s[i].dep_==\"pobj\":\n",
    "            subjects.append(s[i])\n",
    "        elif s[i].head.dep_==\"pobj\": # walk one step up the dependency tree \n",
    "            subjects.append(s[i])\n",
    "        else:\n",
    "            continue\n",
    "    return subjects\n",
    "\n",
    "def check_synonym_acl(s, list_):\n",
    "    for token in s:\n",
    "        if token.dep_==\"acl\":\n",
    "            lem=token.lemma_\n",
    "            if lem in list_:\n",
    "                return True\n",
    "            else:\n",
    "                return False  \n",
    "\n",
    "def find_obj_acl(s, ind):\n",
    "    subjects=[]\n",
    "    for i in ind:\n",
    "        if s[i].dep_==\"pobj\":\n",
    "            subjects.append(s[i])\n",
    "        elif s[i].head.dep_==\"pobj\": # walk one step up the dependency tree \n",
    "            subjects.append(s[i])\n",
    "        else:\n",
    "            continue\n",
    "    return subjects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b1c1566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4]\n",
      "[0, 2, 4]\n",
      "[0, 4, 8]\n",
      "[3]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# assume we take all root verbs\n",
    "tuples=[]\n",
    "relation=\"is_owner\"\n",
    "synonyms=[\"buy\",\"acquire\",\"purchase\",\"own\"]\n",
    "test=nlp(\"Twitter was bought by Facebook. Facebook owns Instagram and Whatsapp. Instagram and its owner Facebook want to buy Tiktok. Apple competes with Microsoft. John bought Michelle a candy.\")\n",
    "ents=list_entities(test)\n",
    "for s in test.sents:\n",
    "    dict_={}\n",
    "    org=find_org(s,ents)\n",
    "    print(org)\n",
    "    if len(org)>=2:\n",
    "        SVO=check_synonym_SVO(s,synonyms)\n",
    "        if SVO==True:\n",
    "            sbj=find_sbj(s,org)\n",
    "            if len(sbj)>0: \n",
    "                obj=find_obj(s,org)\n",
    "                if len(obj)>0:\n",
    "                    dict_['relation']=relation\n",
    "                    ## add ID later dict_['relation']\n",
    "                    dict_['sentence']=s\n",
    "                    dict_['entities_A']=sbj\n",
    "                    dict_['entities_B']=obj\n",
    "                    tuples.append(dict_)\n",
    "            else:\n",
    "                nsubjpass=find_nsubjpass(s,org)\n",
    "                if len(nsubjpass)>0:\n",
    "                    obj=find_obj(s,org)\n",
    "                    if len(obj)>0:\n",
    "                        dict_['relation']=relation\n",
    "                        ## add ID later dict_['relation']\n",
    "                        dict_['sentence']=s\n",
    "                        dict_['entities_A']=obj\n",
    "                        dict_['entities_B']=sbj\n",
    "                        tuples.append(dict_)\n",
    "                else:\n",
    "                    continue\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf6ef3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'relation': 'is_owner',\n",
       "  'sentence': Twitter was bought by Facebook.,\n",
       "  'entities_A': [Facebook],\n",
       "  'entities_B': []},\n",
       " {'relation': 'is_owner',\n",
       "  'sentence': Facebook owns Instagram and Whatsapp.,\n",
       "  'entities_A': [Facebook],\n",
       "  'entities_B': [Instagram, Whatsapp]}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f309b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c1d363e",
   "metadata": {},
   "source": [
    "# attributes kind of patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94e3a32",
   "metadata": {},
   "source": [
    "This pattern allow us to filter via the \"attr\", we select a list of words that shall correlate with the relation in question and filter the entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74f588df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Facebook   NNP      nsubj        are PROPN\n",
      "       and    CC         cc   Facebook CCONJ\n",
      " Instagram   NNP       conj   Facebook PROPN\n",
      "       are   VBP       ROOT        are AUX\n",
      "competitors   NNS       attr        are NOUN\n",
      "        of    IN       prep competitors ADP\n",
      "    Tiktok   NNP       pobj         of PROPN\n",
      "       and    CC         cc     Tiktok CCONJ\n",
      "   Twitter   NNP       conj     Tiktok PROPN\n"
     ]
    }
   ],
   "source": [
    "test3=nlp(\"Facebook and Instagram are competitors of Tiktok and Twitter\")\n",
    "for s in test3.sents:\n",
    "    for token in s:\n",
    "        print('%10s %5s %10s %10s %s'%(token.text, token.tag_, token.dep_, token.head, token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b1001d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Engie    NN      nsubj         is NOUN\n",
      "        is   VBZ       ROOT         is AUX\n",
      "         a    DT        det   supplier DET\n",
      "  supplier    NN       attr         is NOUN\n",
      "        of    IN       prep   supplier ADP\n",
      "      many    JJ       amod businesses ADJ\n",
      "businesses   NNS       pobj         of NOUN\n"
     ]
    }
   ],
   "source": [
    "test3=nlp(\"Engie is a supplier of many businesses\")\n",
    "for s in test3.sents:\n",
    "    for token in s:\n",
    "        print('%10s %5s %10s %10s %s'%(token.text, token.tag_, token.dep_, token.head, token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37ce160a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Facebook   NNP      nsubj         is PROPN\n",
      "        is   VBZ       ROOT         is AUX\n",
      "         a    DT        det    company DET\n",
      "   company    NN       attr         is NOUN\n",
      "      from    IN       prep    company ADP\n",
      "      Meta   NNP   compound      group PROPN\n",
      "     group    NN       pobj       from NOUN\n"
     ]
    }
   ],
   "source": [
    "test3=nlp(\"Facebook is a company from Meta group\")\n",
    "for s in test3.sents:\n",
    "    for token in s:\n",
    "        print('%10s %5s %10s %10s %s'%(token.text, token.tag_, token.dep_, token.head, token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62005510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4]\n",
      "[0]\n",
      "[0, 5]\n",
      "[0, 7]\n"
     ]
    }
   ],
   "source": [
    "tuples=[]\n",
    "relation=\"is_owner\"  # note: adapt for one way relationships\n",
    "synonyms=[\"company\",\"firm\",\"branch\"]\n",
    "test=nlp(\"Twitter was bought by Facebook. Engie is a supplier of RATP. Facebook is a company from Meta group. Engie is a firm that competes with EDF.\")\n",
    "ents=list_entities(test)\n",
    "for s in test.sents:\n",
    "    dict_={}\n",
    "    org=find_org(s,ents)\n",
    "    print(org)\n",
    "    if len(org)>=2:\n",
    "        attr=check_synonym_attr(s,synonyms)\n",
    "        if attr==True:\n",
    "            sbj=find_sbj(s,org)\n",
    "            if len(sbj)>0: \n",
    "                obj=find_obj_attr(s,org)\n",
    "                if len(obj)>0:\n",
    "                    dict_['relation']=relation\n",
    "                    ## add ID later dict_['relation']\n",
    "                    dict_['sentence']=s\n",
    "                    dict_['entities_A']=sbj\n",
    "                    dict_['entities_B']=obj\n",
    "                    tuples.append(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "affd724a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'relation': 'is_owner',\n",
       "  'sentence': Facebook is a company from Meta group.,\n",
       "  'entities_A': [Facebook],\n",
       "  'entities_B': [Meta]},\n",
       " {'relation': 'is_owner',\n",
       "  'sentence': Engie is a firm that competes with EDF.,\n",
       "  'entities_A': [Engie],\n",
       "  'entities_B': [EDF]}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ab2f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b74b24b",
   "metadata": {},
   "source": [
    "# ACL based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f39d01f",
   "metadata": {},
   "source": [
    "A clausal modifier of noun (acl) is either an infinitive clause, a participial clause, or a clausal complement that modifies the head of a noun phrase.\n",
    "Ex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b885cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Instagram   NNP      nsubj        was PROPN\n",
      "       was   VBD       ROOT        was AUX\n",
      "       the    DT        det    company DET\n",
      "   company    NN       attr        was NOUN\n",
      "  acquired   VBN        acl    company VERB\n",
      "        by    IN      agent   acquired ADP\n",
      "  Facebook   NNP       pobj         by PROPN\n"
     ]
    }
   ],
   "source": [
    "test=nlp(\"Instagram was the company acquired by Facebook\")\n",
    "for s in test.sents:\n",
    "    for token in s:\n",
    "        print('%10s %5s %10s %10s %s'%(token.text, token.tag_, token.dep_, token.head, token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "038e0a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Instagram   NNP      nsubj         is PROPN\n",
      "         ,     ,      punct  Instagram PUNCT\n",
      "       the    DT        det    company DET\n",
      "   company    NN      appos  Instagram NOUN\n",
      "    bought   VBN        acl    company VERB\n",
      "        by    IN      agent     bought ADP\n",
      "  Facebook   NNP       pobj         by PROPN\n",
      "         ,     ,      punct  Instagram PUNCT\n",
      "        is   VBZ       ROOT         is AUX\n",
      "         a    DT        det      media DET\n",
      "    social    JJ       amod      media ADJ\n",
      "     media   NNS       attr         is NOUN\n",
      "         .     .      punct         is PUNCT\n"
     ]
    }
   ],
   "source": [
    "test=nlp(\"Instagram, the company bought by Facebook, is a social media.\")\n",
    "for s in test.sents:\n",
    "    for token in s:\n",
    "        print('%10s %5s %10s %10s %s'%(token.text, token.tag_, token.dep_, token.head, token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "747ba188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter was bought by Facebook.\n",
      "[0, 4]\n",
      "Instagram, the company bought by Facebook, is a social media.\n",
      "[6]\n",
      "Facebook is a company from Meta group.\n",
      "[0, 5]\n",
      "Instagram was the company acquired by Facebook.\n",
      "[6]\n"
     ]
    }
   ],
   "source": [
    "tuples=[]\n",
    "relation=\"is_owner\"  # note: adapt for one way relationships\n",
    "synonyms=[\"buy\",\"acquire\",\"purchase\",\"own\"]\n",
    "test=nlp(\"Twitter was bought by Facebook. Instagram, the company bought by Facebook, is a social media. Facebook is a company from Meta group. Instagram was the company acquired by Facebook.\")\n",
    "ents=list_entities(test)\n",
    "for s in test.sents:\n",
    "    print(s)\n",
    "    dict_={}\n",
    "    org=find_org(s,ents)\n",
    "    print(org)\n",
    "    if len(org)>=2:\n",
    "        acl=check_synonym_acl(s,synonyms)\n",
    "        if acl==True:\n",
    "            sbj=find_sbj(s,org)\n",
    "            if len(sbj)>0: \n",
    "                obj=find_obj_acl(s,org)\n",
    "                if len(obj)>0:\n",
    "                    dict_['relation']=relation\n",
    "                    ## add ID later dict_['relation']\n",
    "                    dict_['sentence']=s\n",
    "                    dict_['entities_A']=sbj\n",
    "                    dict_['entities_B']=obj\n",
    "                    tuples.append(dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "298a58e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f671f51",
   "metadata": {},
   "source": [
    "Tuples empty because spacy does not recognize Instagram as entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770b5b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c5ddfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d959a234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb997a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236660a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11af1199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cad48ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacy",
   "language": "python",
   "name": "spacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
